# src/config/model_config.yaml
model:
  vocab_size: 256 # For raw bytes/chars (0-255 ASCII/Unicode subset)
  embedding_dim: 128
  num_layers: 4
  num_heads: 8
  block_size: 256 # Reduced from 512. Max input sequence length for raw encoder

raw_encoder:
  type: "text"  # Default: text-only
  text:
    char_embed_dim: 32
    multi_freq_components: 3
  image:
    enabled: false  # Set to true for image input
    input_shape: [3, 224, 224]  # C, H, W - Expected shape for UniversalRawImageEncoder
  audio:
    enabled: false  # Set to true for audio input
    sample_rate: 16000  # For reference, not used in custom encoder directly
    num_samples: 131072  # 128 segments * 1024 window_size (approx for custom encoder)

dynamic_resolution:
  min_res_scale: 0.1 # Minimum resolution scale (e.g., for attention dropout)
  max_res_scale: 1.0 # Maximum resolution scale
  threshold_for_boost: 0.5 # Focus strength threshold for resolution boost

output_convergence:
  convergence_temp_min: 0.1 # Minimum temperature for sampling (more decisive)
  convergence_temp_max: 1.0 # Maximum temperature for sampling (more exploratory)
  convergence_top_p_min: 0.1 # Minimum top_p for sampling
  convergence_top_p_max: 0.9 # Maximum top_p for sampling
  
training:
  learning_rate: 0.001
  batch_size: 8 # Reduced from 16
  num_epochs: 5
  eval_interval: 10 # Reduced from 100 for more frequent logging
  seed: 42 # New: Seed for reproducibility
